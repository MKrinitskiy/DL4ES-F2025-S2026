# DL4ES: Занятие 7

## Практическое занятие: создание и обучение нейросетей в PyTorch (продолжение)

В этой лекции студенты подробно познакомились с тем, как на практике создаются и обучаются искусственные нейронные сети в фреймворке PyTorch. Мы разобрали, как описывается архитектура модели, как формируются слои, как задаются размерности входов и выходов, и каким образом PyTorch автоматически строит вычислительный граф. Особое внимание уделялось тому, как параметры сети становятся тензорами, по которым могут вычисляться градиенты, и как последовательно организуются преобразования внутри нейросети.

Отдельный блок занятия был посвящён устройству процесса стохастической оптимизации. Мы рассмотрели понятия батча и эпохи, разобрали механику мини-батчового градиентного спуска и обсудили стратегии сэмплирования данных. На примере синтетической задачи было показано, какие шаги выполняются на каждой итерации: прямой проход, вычисление функции потерь, запуск обратного распространения ошибки и выполнение шага оптимизатора. Обсуждалось, почему часть вычислений имеет смысл выполнять только после завершения эпохи — например, оценку качества модели на валидационной выборке.

В финале лекции была подчеркнута связь изученного материала с последующими темами курса. Понимание механики PyTorch, структуры вычислительного графа и организации цикла обучения является необходимой базой для работы с более сложными архитектурами, оптимизаторами и методами диагностики моделей, которые будут рассмотрены на следующих занятиях.

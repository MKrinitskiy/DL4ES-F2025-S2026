# DL4ES: Занятие 6

## Практическое построение и обучение нейросетей в PyTorch

В этой лекции студенты впервые познакомились с полноценной практикой построения и обучения искусственных нейронных сетей на примере фреймворка PyTorch. Основной акцент был сделан на том, как устроена нейросеть на уровне кода: от создания архитектуры и описания слоёв до прохождения данных через модель и вычисления функции потерь. Особое внимание уделялось тому, как параметры сети становятся частью вычислительного графа и каким образом PyTorch автоматически определяет, где нужно считать градиенты.

Второй важный блок занятия был посвящён механике стохастической оптимизации. Разбирались понятия батча, эпохи, особенности сэмплирования данных, а также различия между градиентным спуском и стохастическим его вариантом. На примере синтетической задачи показано, как формируется цикл обучения, что выполняется на каждой итерации и почему некоторые проверки и вычисления проводятся только после завершения эпохи.

В завершение занятия обсуждалось практическое применение полученных знаний: работа с MNIST, настройка оптимизаторов, анализ параметров модели и подсчёт их количества, а также методы визуализации качества обучения. Лекция стала фундаментом для следующего практического занятия, на котором будет подробно разобран цикл обучения и механизм оптимизаторов. 


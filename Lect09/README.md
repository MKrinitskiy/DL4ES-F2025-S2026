# DL4ES 2025: Лекция 9

## Импульсный метод, скрытые представления и шум в оптимизации нейросетей

В этой лекции мы разобрали две важные линии развития современного глубокого обучения: мониторинг внутренних процессов модели и эволюцию методов градиентной оптимизации. С одной стороны, мы научились наблюдать распределения весов, градиентов и скрытых представлений через TensorBoard, что позволяет глубже понимать динамику обучения и диагностировать проблемы. С другой стороны, мы увидели, почему классический градиентный спуск почти не используется в практике — его заменили устойчивые стохастические методы, способные справляться с шумностью и сложным ландшафтом функции потерь.

Особенное внимание было уделено концепции скрытых представлений: что считать скрытым слоем, как они устроены, какие имеют размерности и почему их распределения важны. Эти распределения отражают, насколько слои сети «живы», не затухают ли градиенты и не вырождаются ли параметры. Добавление их гистограмм в TensorBoard — важный шаг к профессиональному анализу качества обучения.

Вторая часть лекции погрузила нас в особенности стохастического градиентного спуска, вытянутые долины ландшафта ошибок и импульсный метод (momentum), который сглаживает осцилляции и помогает продвигаться к минимуму более устойчиво. Это важная подготовка к следующему шагу — изучению алгоритмов **RMSProp** и **Adam**, которые стали стандартом обучения современных нейросетей.

# DL4ES 2025: Лекция 8, план-конспект

## Tensorboard: мониторинг обучения нейросетей

## 1. Введение
- Организационные моменты.
- Цели занятия: завершение блока по базовой архитектуре и обучению нейросетей в PyTorch.
- Переход от “понять код” → к “понимать процесс обучения и мониторинга”.

## 2. Напоминание материала предыдущего занятия
- Полный цикл работы с нейросетью:
  - Формулировка модели.
  - Запуск обучения.
  - Завершение обучения.
  - Процедура валидации.
- Повторение ключевого: мы записывали значение функции потерь на каждой эпохе и могли строить график после завершения обучения.

## 3. Почему мониторинг обучения критически важен
- Нейросети обучаются значительно дольше, чем классические ML-модели.
- Примеры времени обучения:
  - Простая MLP: 20–30 минут.
  - Средние модели: часы.
  - Большие модели: несколько суток.
  - Foundation-модели (GPT и др.): месяцы.
- Важность мониторинга обучения:
  - Нельзя "оставить вслепую".
  - Нужны инструменты отслеживания прогресса: функция потерь, метрики, стабильность.

## 4. CPU vs GPU. Перенос тензоров на устройства
- PyTorch-архитектура исполнения:
  - Jupyter Notebook лишь оболочка; вычисления происходят в Python-процессе.
- Ключевые моменты:
  - GPU используется, только если он есть в системе.
  - Тензоры можно явно перемещать `.cuda()` или `.to(device)`.
  - Если модель на CPU, а данные на GPU — ошибка: операции на разных устройствах.
  - Все тензоры модели и данные должны быть на одном устройстве.

### 4.1. Тензоры в PyTorch
- Тензоры = многомерные матрицы + дополнительные атрибуты.
- Ключевой атрибут: `requires_grad`.
- Хранение градиентов: `.grad` имеет ту же форму, что и тензор.
- Влияние на производительность.

### 4.2. Передача тензоров между устройствами
- `.cuda()`, `.cpu()`, `.to(device)`.
- Почему избегают лишних передач: медленно.
- Передавать только минимум (обычно итоговые скаляры).

## 5. Организация вычислений на GPU
- Где bottlenecks:
  1. Чтение данных с диска — *самый медленный этап*.
  2. Аугментация / препроцессинг на CPU.
  3. Передача данных CPU→GPU.
  4. Только затем — сами матричные операции (самые быстрые).
- Принципы:
  - Ускорять чтение и аугментацию.
  - Делать препроцессинг на PyTorch, если возможно.
  - Минимизировать передачи данных.
  - Обеспечивать высокую загрузку GPU.

## 6. Мониторинг загрузки GPU
- Использование `nvidia-smi`:
  - Температура.
  - Потребляемая мощность.
  - GPU Utilization.
  - Использование памяти.
- Как интерпретировать:
  - Если GPU загружена 0–10 % — модель простаивает, CPU не успевает подавать данные.
  - Идеал — постоянная высокая загрузка.

## 7. TensorBoard в PyTorch
- TensorBoard — изначально инструмент TensorFlow.
- В PyTorch используется через `torch.utils.tensorboard`.
- Два компонента:
  1. **SummaryWriter** — записывает логи.
  2. **TensorBoard сервер** — визуализирует логи.

### 7.1. Что пишем в TensorBoard
- Значения функции потерь:
  - На каждом батче.
  - На каждой эпохе.
- Метрики:
  - Accuracy на валидации.
- В перспективе — гистограммы весов и активаций.

### 7.2. Что показывает TensorBoard
- Эволюцию loss:
  - На батчах — шумно.
  - На эпохах — сглажено.
- Эволюцию accuracy.
- Возможность включать логарифмический масштаб.
- Обновление графиков в реальном времени.

## 8. Поведение функции потерь и критерии остановки
- Loss по батчам “волосатый”.
- Loss по эпохам — ключевой ориентир.
- Снижение может продолжаться долго → полезно ставить:
  - Early stopping.
  - Ограничение по времени.
  - Ограничение по эпохам.
  - Внешний сигнал остановки (файл-флаг).

## 9. Сохранение лучшей модели
- Сохранение весов при улучшении качества:
  - Хранится только лучший вариант.
  - Файл `bestmodel.pth`.
- Состояние модели = архитектура + веса.
- Почему сохраняем по улучшению метрики, а не раз в эпоху:
  - Экономия памяти.
  - Консистентность.

## 10. Прерывание обучения
- Способы:
  - Ctrl+C (грубый).
  - Файл-флаг → «мягкая остановка».
  - Внешний таймер.
- Грамотный подход:
  - Проверка на каждой эпохе или батче.
  - Корректное завершение и сохранение логов.

## 11. Пример отслеживания обучения “вживую”
- Запуск обучения на 100 эпох.
- TensorBoard показывает обновления в реальном времени.
- Видно, что насыщение ещё не наступило.
- Демонстрация остановки обучения вручную.

## 12. Заключение лекции
- TensorBoard — основной инструмент мониторинга DL-обучения.
- Глубокое понимание CPU/GPU-пайплайна критично.
- В следующей лекции:
  - Разбор гистограмм TensorBoard (веса, активации).
  - Почему распределения в нейросети важны.
  - Начало обсуждения оптимизации пайплайна загрузки данных.
